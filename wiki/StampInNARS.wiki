#summary The design and function of Stamp in NARS.

= Introduction =

A Stamp (nars.entity.Stamp) serves several related functions in NARS. It is currently a component of a Sentence (nars.entity.Stamp), though conceptually it can also be considered as a component of TruthValue (nars.entity.TruthValue), since it contains information about the validity of a truth-value.

A Stamp contains an _evidential base_, a _derivation chain_, a _creation time_, and an optional _occurrence time_.

= Evidential base =

NARS is designed according to an experience-grounded semantics, and therefore the truth-value of a statement indicates the relation between a statement and certain evidence collected from the system's experience.

The system's experience is the stream of input sentences, each of which is uniquely identified with a serial number, starting from 1. At the current stage, it is assumed that the system will never run out of serial numbers in its lifetime.

The _evidential base_ of a sentence is a list of serial numbers defined above.

For an input sentence, its evidential base contains only the serial number assigned to it when it enters the system.

= Derivation chain =

The derivation chain keeps track of all premises and conclusions in their specific rule-application-steps which leaded to the derivation of the new statement.

Before the revision rule is applied to a pair of candidate premises, the evidential bases of the two are compared, and revision happens only when the two lists are _disjoint_, i.e., have no common element. Before a non-revision rule is applied, to a pair of candidate premises, to derive a new conclusion c, the derivation chain of both premises is checked if it contains c, only if they don't the rule-application will be allowed. This policy is established to prevent the following results:
  * Duplicated evidence. Without restriction, the revision rule could use the same evidence repeatedly to increase the confidence of a conclusion. However, if the same sentence happens multiple times in experience, each instance will get different serial numbers, so can be used by the revision rule to derive more confident conclusions. What is invalidated is multiple usage of the evidental source of a sentence in order to strenghten a statement which depends on the sentence the source claimed with revision.
  * Circular inference. Given the reversibility of the syllogistic rules in NAL, circular inference could happen if no restriction were made when premises are selected for inference. Whenever a new derived conclusion, depends on itself in order to derive itself, this would be faulty circular reasoning which needs to be avoided.
  * Correlated truth-values. Many truth-value functions in NAL are designed under the assumption that the truth-values of the two premises are independent in the sense that known one does not determine, or even bound, the other. When the two evidential bases are disjoint, the independence assumption holds.

The evidential base of the conclusion of two sentences (a belief and the task sentence) is conceptually the union (or concatenation) of their evidental bases, while the deviation chain will also add the two sentences itself. However, it is not directly implemented in this way, otherwise the time and space needed for evidential bases and derivation chains would grow exponentially to the length of the inference chain. Under the assumption of insufficient resources, the maximum size of an evidential base must be a constant (as a system parameter, MAXIMUM_EVIDENTAL_BASE_LENGTH, MAXIMUM_DERIVATION_CHAIN_LENGTH). The evidential bases of the premises are interwoven, then cut at the maximum length.

In this way, the order of elements in the list matters, and the two premises are treated equally. It will not work as well if the list is turned into a set, then the union of two sets are reduced to the maximum size, because in that way the serial numbers in the conclusion may only come from one parent.

Though this design works fine for most cases, it has one limitation:
  * It cannot detect common ancestor beyond the maximum length allows.

= Creation time =

The creation time of a sentence is either when it enters the system (for input sentences), or when it is generated by the system (for derived sentences), indicated using the internal clock that measures time using the inference cycle.

When the system starts, the time is 0. Then it is increased by one in each working cycle. Therefore, it is possible for multiple sentences to have the same Creation time, as long as they are accepted or generated within the same working cycle.

Currently this information is mostly used for debugging, though it will play more important roles when NAL-7 is implemented.

= Occurrence time =

This component will be needed to implement temporal inference specified in NAL-7. More details will be added later.