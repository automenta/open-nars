#summary New functions of Open-NARS version 1.6.x.


= Introduction =

Open-NARS 1.6.x is different from 1.5.x in the following major aspects:
  # In logic, it implements NAL-7, NAL-8, and NAL-9, and therefore completely implements NAL, as specified in [http://www.worldscientific.com/worldscibooks/10.1142/8665 Non-Axiomatic Logic: A Model of Intelligent Reasoning]. It is an attempt to re-do what [OpenNarsOneDotFour] planned to achieve.
  # In control, it refines the automatic resources allocation that has been there from the beginning, and combines it with the voluntary control introduced in NAL-9.
  # In software structure, it absorbs the ideas from previous discussions (such as in [AbstractDesignProposal], [Modules], [GUIRequest]) and implementations (the version built by Joe Geldart), as well as the recent discussions.


= Temporal Inference (NAL-7) =

===Representation of temporal information===

Beside [http://www.worldscientific.com/worldscibooks/10.1142/8665 Non-Axiomatic Logic: A Model of Intelligent Reasoning], temporal reasoning in NARS is also discussed in [http://www.cis.temple.edu/~pwang/Publication/temporal-causal.pdf Issues in Temporal and Causal Inference]. A previous implementation exists as version 1.3.3, with [https://code.google.com/p/open-nars/source/browse/trunk/nars-dist/Examples-1.3.3/Example-NAL7-abridged.txt working examples].

Beside using terms whose meanings are explicitly temporal, Narsese is extended to allow temporal order among components in certain CompoundTerm, as well as an "occurrence time stamp" on a truth-value.

In package nars.language, the following three classes representing compound terms will be given an optional temporal order among its components: _Implication_, _Equivalence_, and _Conjunction_. This order can be represented either as subclasses, or as an attribute that takes three possible values: -1 for backward, +1 for forward, 0 for concurrent, and 2 for "no temporal order". These numbers are selected to make the later processing easy and natural, so should not be changed unless after careful consideration. The plain text forms of the term connectors are listed in [InputOutputFormat].

In class nars.entity.Stamp, an occurrenceTime records the (observed, remembered, or estimated) occurrence time of the event, together with its creation time. Different from the description in the book, the "tense" of a sentence is not stored with a sentence, but is only used at the interface. When a sentence is an input or output, the internal occurrenceTime will be translated to/from the external sense that is explicitly expressed in Narsese, as listed in [InputOutputFormat].

A system parameter DURATION is used to define the "present tense" as for events with an occurrenceTime in the [-DURATION, DURATION] neighborhood of the current time, as given by the system's internal clock. It's current default value is 5. The previous idea is to take 1 as its value, so "presently" means the current working cycle, but it seems too restrictive.  For an input judgment, if its tense is "present", its occurrenceTime will be set to the current time on the internal clock, "past" is mapped to "current time - DURATION", and "future" to "current time + DURATION". If no tense is used, the occurrenceTime takes a special value ETERNAL. The reverse mapping is used for output.

===Inference on temporal order===

As explained in the publications, temporal inference in NARS is designed by processing the logical and the temporal aspects separately. Therefore all the existing rules will be kept, except that the conclusion may contain a temporal term (with temporal order among components), a time interval (similar to the numbers in experience), and/or a temporal truth-value (with an occurrence time).

The temporal order in CompoundTerms is processed in the following way:
  # As described in the book, each inference rule of NAL-6 is extended by using the temporal copulas and connectors to replace the atemporal ones in the premises, then identifying the conclusions where both the logical and the temporal relations can be derived, so as to establish valid inference rules for NAL-7.
  # Different from what is hinted in the book, the temporal order is taken to be binary, not multi-valued, so the matter of degree in the truth-value is completely caused by the logical factor, not the temporal factor. For this reason, in all inference rules (both strong and weak), the temporal order among the terms in the conclusion is the same order as those terms in the premises. If no such a temporal order can be decided in a certain combination of the terms, no conclusion is derived.

===Inference on occurrence time===

In most rules, the occurrenceTime is processed independent of the other aspects of the rule. There are the following cases:
  * If both premises are ETERNAL, so is the conclusion. Therefore all the inference rules defined in the lower layers remain valid.
  * If the task is "tensed" (i.e., with an occurrenceTime that is not ETERNAL) but the belief is not, then the conclusion has the same occurrenceTime as the tensed premise.
  * If the task is not tensed but the belief is, then an _eternalization_ rule is used to take the belief as providing evidence for the sentence in the task.
  * If both premises are tensed, then the belief is "projected" to the occurrenceTime of the task. Ideally, temporal inference is valid only when the premises are about the same moment, i.e., have the same occurrenceTime or no occurrenceTime (i.e., eternal). However, since occurrenceTime is an approximation and the system is adaptive, a conclusion about one moment (that of the belief) can be projected to another (that of the task), at the cost of a confidence discount. Let _t0_ be the current time, and _t1_ and _t2_ are the occurrenceTime of the premises, then the discount factor is _d_ = 1 - |_t1-t2_| / (|_t0-t1_| + |_t0-t2_|), which is in [0,1]. This factor _d_ is multiplied to the confidence of a promise as a "temporal discount" to project it to the occurrence of the other promise, so as to derive a conclusion about that moment. In this way, if there are conflicting conclusions, the temporally closer one will be preferred by the choice rule.

*Issue*: The above formula looks natural, though there are still some issues to be resolved. For example, when _t1_ or _t2_ equals _t0_, _d_ will be 0. It may be possible to resolve this issue via eternalization.

In principle, all inference rules should take temporal information into account. However, since an inference rule may be implemented as the cooperation of multiple methods, which not all of them will be responsible to check temporal information.

Normally, if the premises are "tensed", so is the conclusion --- the knowledge derived about a moment is only valid for that moment. It is through "eternalization" that an eternal conclusion is arrived, at the cost of a confidence lost.

===Temporal induction and detachment===

An inference where temporal order and occurrence time are tangled is temporal induction and its reverse, detachment (as special case of deduction and abduction).

In NARS, temporal induction refers to the situation where events _e1_ and _e2_ are observed as occurring in succession, with a time interval in between with a length of _n_ clock cycles. As far as this sequence of events is noticed by the system, an inductive conclusion _(&/,e1,interval(n)) =/> e2_ is derived.

There are still several issues about this inference.

*Issue*: This rule is one of the exceptions of the "generalized syllogistic" pattern in NAL inference rules, which requires the premises to have a common term. This pattern guarantees the semantic relevance among the statements involved, and also greatly reduced the number of legal combinations of premises. The current exception is allowed, because the two events are related _temporally_, though not semantically, and in future works on sensation organs similar exceptions will be allowed for _spatially_ related events to be combined into compound events without shared components. However, it raises a problem on variable introduction. If _e1_ and _e2_ have common subject or predicate, it seems natural to introduce an independent variable, but what if the common term occupies other positions?

*Issue*: Another problem is about the time interval _n_ between the two events. To simply derive _e1 =/> e2_ is correct, but does not capture the temporal information about the interval. To use another event to represent the interval (as tried in version 1.3.3) is too accurate to be useful, because _(&/,e1,interval(100)) =/> e2_ and _(&/,e1,interval(101)) =/> e2_ probably should be merged by the revision rule, since the difference between the two numbers are negligible. For this consideration, in the current implementation, the interval is represented by a special type of term, which approximately record _m = log(n)_ as an integer. With such a belief as premise, the detachment rule will do deduction with _e1_, and abduction with _e2_, and the occurrenceTime of the conclusion is calculated from that of the other event, plus or minus _exp(m)_ to approximately recover the _n_ value. Whether the log/exp functions should be replaced by power functions (such as sqrt/square) is a question to be answered later.
 
As in other places, whenever an accurate time interval is needed, it is always possible to replace the approximate time interval by a better defined event, so that is not an issue.

*Issue*: Whether to derive conclusions like _e2 =\> (&/,e1,interval(n))_?

*Issue*: Whether to allow interval terms _interval(n)_ to appear in I/O (and in Narsese grammar), when the measurement _n_ is completely subjective?

*Issue*: In the current implementation, the _e1_ and _e2_ are the mostly noticeable events at the previous moment and the current moment, respectively. It may be necessary to change this premise-selection policy.

*Issue*: Because of the change in design, all examples for NAL-7 need to be checked and revised. Some examples should be added to cover the new functions.


= Procedural Inference (NAL-8) =

Beside [http://www.worldscientific.com/worldscibooks/10.1142/8665 Non-Axiomatic Logic: A Model of Intelligent Reasoning], procedural reasoning in NARS is also discussed in [http://www.degruyter.com/view/j/jagi.2012.3.issue-3/v10229-011-0021-5/v10229-011-0021-5.xml?format=INT Solving a Problem With or Without a Program]. A previous implementation exists as version 1.3.3, with [https://code.google.com/p/open-nars/source/browse/trunk/nars-dist/Examples-1.3.3/ working examples in several files], as well as descriptions in [ProceduralInference], [ProceduralExamples], and [ProceduralLearning].

=== Inference on goals ===

In nars.entity.Sentence, a "desire" value is added, which is truth-value interpreted differently. The desire-value of statement _S_ is the truth-value of _S==>D_, where _D_ is a _virtual_ statement representing a desired situation. Furthermore, add "Goal" and "Query" as two types of Sentence, and process them like "Judgment" and "Question", but using desire-value, rather than truth-value.

In all the inference rules, "Query/Goal" and "Judgment/Question" are processed in parallel. Most of the code for this already exist in 1.3.3, and only minor revisions are made.

Given the reversibility of the inference rules of NAL, the derivation of Goals and Quests are basically the existing rules, except that the desire-values are calculated using different functions, according to the above correspondence between truth-value and desire-value. 

*Issue*: Testing examples are needed for the inference on goal and query. The calculations of truth-value and/or budget value in some rules may be incorrect.

Though both Question and Goal are derived by backward inference, there is a major difference between the two: while derived Questions are directly accepted as new tasks, derived Goals do not immediately become tasks. instead, they contribute to the desirability of the corresponding sentences. Only when the desirability of a sentence reach a threshold, does a decision-making rule is triggered to decide whether to pursue the sentence as a goal.

*Issue*: In the current version, the decision-making rule only take the desire-value into account, while as described in the book, the plausibility of the goal should be considered, too. The problem is to find a reasonable way to calculate it.

*Issue*: The inference on Quest, as Question on desire-values, has not been carefully evaluated. In particular, the budget-value functions need to be properly selected in each rule, since in the same method, the selection may be different between Quest and Question on truth-value.

=== Inference on operations ===

Goals are eventually achieved by the execution of operations. An "operation" package is introduced, with each operator defined as a class, with an "execute" method that takes a list of arguments for the operation. In Memory, a HashMap<String, Operator> is used to associate the operators with their names. When a goal corresponds to an operation, the _execute_ method of its operator is called.

An operation with acquired operator _oper_ and arguments _args_ is internally represented as an Inheritance statement _(`*`, SELF, args) --> oper_, though at the I/O interface it is displayed as _(oper, args)_. Here _SELF_ is a special term representing the system itself.

*Issue*: Technically, _(`*`, SELF, args) --> oper_ and _(`*`, args, SELF) --> oper_ both work as the internal representation of an operation. The former looks more natural (so is used in the book), while the latter is slightly more efficient (so is used in the code). A final decision will need to be made to keep the descriptions consistent.

*Issue*: Because of the changes in NAL-7, the temporal aspects of all NAL-8 examples need to be checked and revised.

=== Operational interface ===

A "universal sensorimotor interface" is provided in class Operator.java, where the commands or functions of other systems or decides can be registered in NARS, and called by it. With each operator, some initial knowledge about its preconditions and consequences should be provided to the system, so inference can be carried out on it.

As an example, a _nars.operator.math_ package is defined to contain some simple math operators. Currently there are two operators, which can be called as "(`^`count, {a, b, c}, #x)!" and "(`^`add, 2, 3, #x)!", where _#x_ will be replaced by the result after the execution, as "(`^`count, {a, b, c}, 3)." and "(`^`add, 2, 3, 5)." To embed them into knowledge, the input arguments should be independent variables, such as "... (`^`count, $y, #x) ..." and "... (`^`add, $y, $z, #x) ...". In the future, each group of optional operators should be kept in a sub-package of _nars.operator_, and each class should extend Operator.java, as well as to add a line to call _registerOperator_ in its super class.

In summery, there will be three types of operators in NARS that share the format _(oper, args)_:
  * *Native operators*, the connectors of CompoundTerms that are directly recognized and processed by the grammar rules and inference rules
  * *Standard operators*,  the operators to be introduced in NAL-9, and equipped in every normal NARS implementation
  * *Optional operators*,  the specific operators that turn a standard NARS into a customized NARS+ described in the book

The first two types will be fixed, while the last is extendable. There is a possibility of letting the set of standard operators differ from system to system, though the benefit of this flexibility remains unknown. 


= Introspective Inference (NAL-9) =

A previous preliminary implementation exists as version 1.4.0, and explained briefly in [OpenNarsOneDotFour].

This layer of NAL will be mainly implemented as a set of mental operations whose major consequences are within the system itself. These operations carries out various types of self-monitoring and self-control.

=== Deliberate control ===

The package _nars.operator.mental_ contains operators that allow the system to deliberately override the automatic inference control mechanism:
  * *task creation*: This group of operators each takes a Term as argument, and uses it as content to create a new task to be processed: _`^`believe_ for judgment, _`^`want_ for goal, _`^`wonder_ for question, and _`^`evaluate_ for query. 
  * *truth-value/desire-value correction*: The operators _`^`doubt_ and _`^`hesitate_ each takes a Term as argument, find the corresponding Concept, then reduce the confidence by _Parameters.DISCOUNT_RATE_ of all the truth-values and desire-values, respectively. These operations are used when the system realized that some previous evidence is unreliable or unjustified. Please note that no operator is needed to increase the confidence value, because it can be achieved by the revision rule with new evidence.
  * *compound compiling*: The operators _`^`name_ and _`^`abbreviate_ both builds a similarity relation with high confidence between a compound term and an atomic term, so as to reduce the syntactic complexity of the corresponding concept. Their difference is that _`^`name_ takes a given atomic term as the second argument, while _`^`abbreviate_ makes a new internal name.
  * *concept activation*: The operators _`^`remind_ increases the priority of a specified concept; _`^`consider_ directly carries out an inference cycle on a specified concept.
  * *operator binding*: The operators _`^`register_ add a new operator when the system is running.

The name of a mental operator only roughly corresponds to its meaning. The exact meaning of an operator is revealed by its preconditions and consequences.

These mental operators are introduced for experimental purpose. The details in each of them may be revised, and other operators may be introduced. In general, each operator should be relatively simple and meaningful. It is neither necessary nor possible for the system to explicitly manage all its internal actions, so it is not a good idea to define a large number of mental operators.

*Issue*: There are some I/O operations to be coded, as listed in Operator.java as comments.

=== Feeling and emotion ===

While the above operations work on individual data items like a sentence or a concept, there are also operators that work on the system as a whole.

There are a few indicators used to measure the current status of the system:
  * _happyValue_: a summary of the satisfaction values (i.e., the quality of its current solution) of the recently pursued goals
  * _busyValue_: a summary of the priority values of the recently processed tasks

Both are updated by taking a weighted average of its previous value and a new value, so as to represent the "recent" situation.

The "feeling" operations report the corresponding value. For example, a goal _(`^`feelHappy)!_ is rewritten into _<(`*`,SELF) --> `^`feelHappy>!_ in the system, and then the result is an input judgment like _<{SELF} --> `[`Happy`]`>._  where the frequency is the current value in that sensation. Now the system's experience includes internal sensations, which are processed in the same way as the sensations about the outside events.

*Issue*: It is maybe necessary to keep a list of reserved words, and to prevent them from being misused. Currently there are "Happy", "Busy", and "SELF".

*Issue*: It will be necessary to call the corresponding operations to answer related questions, such as _<{SELF} --> `[`Happy`]`>?_

*Issue*: The desire-value of non-statement terms should also be used to prepare the system's attitude toward the term. For example, if the occurrence of concept _bird_ is usually associated with the satisfaction of goals (or, equivalently, high happyValue), then it will have a relatively high desire-value, and is considered as to be "liked" by the system. This feature can be checked by certain operator, like _`^`feelLike_, and taken into account in decision making.

This group of operator all extend Feel.java, and each returns a judgment of the pattern _<{SELF} --> `[`Xyz`]`>. :|:_, while the corresponding operator is _(`^`feelXyz)!_ with "Xyz" being the name of the feeling.

NARS only directly measure some fundamental feelings, from which many complicated ones can be built.

*Issue*: Feelings should be used in the system's self-control process to improve the system's efficiency and attention allocation, by producing quick processing of crucial tasks.

*Issue*: It may be interesting to show "emotions" (i.e., the current happyValue and busyValue) in the GUI, though there is no theoretical necessity to do so.

=== Internal experience ===

As mentioned above, the internal experience of the system will include the feedback of the mental operations.

Beside that, it will also be necessary to record the major events within the system, and make it available to the inference. For this purpose, the current inference log will become partially perceivable by the system itself via certain feeling operations, or, some events will even automatically get into the internal experience, so as to allow the system to answer questions like "What I have been thinking?" or "what methods I've tried on that problem?".

To achieve this purpose, an inference step can be summarized afterwards as an Implication statement from the premise(s) to the conclusion.

*Issue*: For double-premise inference rules, it may be better to only include one premise (the task) in the summarizing Implication statement, while taking the other one (the belief) as part of the background knowledge.

The internal experience may be treated similarly as the I/O channels, with a buffer and other features, though there is probably only one such channel.

*Issue*: Whether it is necessary to have a single data structure corresponding to the "flow of consciousness" of the system?
 