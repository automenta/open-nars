#summary New functions of Open-NARS version 1.6.x.


= Introduction =

Open-NARS 1.6.x is different from 1.5.x in the following major aspects:
  # In logic, it implements NAL-7, NAL-8, and NAL-9, and therefore completely implements NAL, as specified in [http://www.worldscientific.com/worldscibooks/10.1142/8665 Non-Axiomatic Logic: A Model of Intelligent Reasoning]. It is an attempt to re-do what [OpenNarsOneDotFour] planned to achieve.
  # In control, it refines the automatic resources allocation that has been there from the beginning, and combines it with the voluntary control introduced in NAL-9.
  # In software structure, it absorbs the ideas from previous discussions (such as in [AbstractDesignProposal], [Modules], [GUIRequest]) and implementations (the version built by Joe Geldart), as well as the recent discussions.


= Temporal inference (NAL-7) =

===Representation of temporal information===

Beside [http://www.worldscientific.com/worldscibooks/10.1142/8665 Non-Axiomatic Logic: A Model of Intelligent Reasoning], temporal reasoning in NARS is also discussed in [http://www.cis.temple.edu/~pwang/Publication/temporal-causal.pdf Issues in Temporal and Causal Inference]. A previous implementation exists as version 1.3.3, with [https://code.google.com/p/open-nars/source/browse/trunk/nars-dist/Examples-1.3.3/Example-NAL7-abridged.txt working examples].

Beside using terms whose meanings are explicitly temporal, Narsese is extended to allow temporal order among components in certain CompoundTerm, as well as an "occurrence time stamp" on a truth-value.

In package nars.language, the following three classes representing compound terms will be given an optional temporal order among its components: _Implication_, _Equivalence_, and _Conjunction_. This order can be represented either as subclasses, or as an attribute that takes three possible values: -1 for backward, +1 for forward, 0 for concurrent, and 2 for "no temporal order". These numbers are selected to make the later processing easy and natural, so should not be changed unless after careful consideration. The plain text forms of the term connectors are listed in [InputOutputFormat].

In class nars.entity.Stamp, an occurrenceTime records the (observed, remembered, or estimated) occurrence time of the event, together with its creation time. Different from the description in the book, the "tense" of a sentence is not stored with a sentence, but is only used at the interface. When a sentence is an input or output, the internal occurrenceTime will be translated to/from the external sense that is explicitly expressed in Narsese, as listed in [InputOutputFormat].

A system parameter DURATION is used to define the "present tense" as for events with an occurrenceTime in the [-DURATION, DURATION] neighborhood of the current time, as given by the system's internal clock. It's current default value is 5. The previous idea is to take 1 as its value, so "presently" means the current working cycle, but it seems too restrictive.  For an input judgment, if its tense is "present", its occurrenceTime will be set to the current time on the internal clock, "past" is mapped to "current time - DURATION", and "future" to "current time + DURATION". If no tense is used, the occurrenceTime takes a special value ETERNAL. The reverse mapping is used for output.

===Inference on temporal order===

As explained in the publications, temporal inference in NARS is designed by processing the logical and the temporal aspects separately. Therefore all the existing rules will be kept, except that the conclusion may contain a temporal term (with temporal order among components), a time interval (similar to the numbers in experience), and/or a temporal truth-value (with an occurrence time).

The temporal order in CompoundTerms is processed in the following way:
  # As described in the book, each inference rule of NAL-6 is extended by using the temporal copulas and connectors to replace the atemporal ones in the premises, then identifying the conclusions where both the logical and the temporal relations can be derived, so as to establish valid inference rules for NAL-7.
  # Different from what is hinted in the book, the temporal order is taken to be binary, not multi-valued, so the matter of degree in the truth-value is completely caused by the logical factor, not the temporal factor. For this reason, in all inference rules (both strong and weak), the temporal order among the terms in the conclusion is the same order as those terms in the premises. If no such a temporal order can be decided in a certain combination of the terms, no conclusion is derived.

===Inference on occurrence time===

In most rules, the occurrenceTime is processed independent of the other aspects of the rule. There are the following cases:
  * If both premises are ETERNAL, so is the conclusion. Therefore all the inference rules defined in the lower layers remain valid.
  * If the task is "tensed" (i.e., with an occurrenceTime that is not ETERNAL) but the belief is not, then the conclusion has the same occurrenceTime as the tensed premise.
  * If the task is not tensed but the belief is, then an _eternalization_ rule is used to take the belief as providing evidence for the sentence in the task.
  * If both premises are tensed, then the belief is "projected" to the occurrenceTime of the task. Ideally, temporal inference is valid only when the premises are about the same moment, i.e., have the same occurrenceTime or no occurrenceTime (i.e., eternal). However, since occurrenceTime is an approximation and the system is adaptive, a conclusion about one moment (that of the belief) can be projected to another (that of the task), at the cost of a confidence discount. Let _t0_ be the current time, and _t1_ and _t2_ are the occurrenceTime of the premises, then the discount factor is _d_ = 1 - |_t1-t2_| / (|_t0-t1_| + |_t0-t2_|), which is in [0,1]. This factor _d_ is multiplied to the confidence of a promise as a "temporal discount" to project it to the occurrence of the other promise, so as to derive a conclusion about that moment. In this way, if there are conflicting conclusions, the temporally closer one will be preferred by the choice rule.

*Issue*: The above formula looks natural, though there are still some issues to be resolved. For example, when _t1_ or _t2_ equals _t0_, _d_ will be 0. It may be possible to resolve this issue via eternalization.

===Temporal induction and detachment===

An inference where temporal order and occurrence time are tangled is temporal induction and its reverse, detachment (as special case of deduction and abduction).

In NARS, temporal induction refers to the situation where events _e1_ and _e2_ are observed as occurring in succession, with a time interval in between with a length of _n_ clock cycles. As far as this sequence of events is noticed by the system, an inductive conclusion _(&/,e1,interval(n)) =/> e2_ is derived.

There are still several issues about this inference.

*Issue*: This rule is one of the exceptions of the "generalized syllogistic" pattern in NAL inference rules, which requires the premises to have a common term. This pattern guarantees the semantic relevance among the statements involved, and also greatly reduced the number of legal combinations of premises. The current exception is allowed, because the two events are related _temporally_, though not semantically, and in future works on sensation organs similar exceptions will be allowed for _spatially_ related events to be combined into compound events without shared components. However, it raises a problem on variable introduction. If _e1_ and _e2_ have common subject or predicate, it seems natural to introduce an independent variable, but what if the common term occupies other positions?

*Issue*: Another problem is about the time interval _n_ between the two events. To simply derive _e1 =/> e2_ is correct, but does not capture the temporal information about the interval. To use another event to represent the interval (as tried in version 1.3.3) is too accurate to be useful, because _(&/,e1,interval(100)) =/> e2_ and _(&/,e1,interval(101)) =/> e2_ probably should be merged by the revision rule, since the difference between the two numbers are negligible. For this consideration, in the current implementation, the interval is represented by a special type of term, which approximately record _m = log(n)_ as an integer. With such a belief as premise, the detachment rule will do deduction with _e1_, and abduction with _e2_, and the occurrenceTime of the conclusion is calculated from that of the other event, plus or minus _exp(m)_ to approximately recover the _n_ value. Whether the log/exp functions should be replaced by power functions (such as sqrt/square) is a question to be answered later.
 
As in other places, whenever an accurate time interval is needed, it is always possible to replace the approximate time interval by a better defined event, so that is not an issue.


= Procedural inference (NAL-8) =

Beside [http://www.worldscientific.com/worldscibooks/10.1142/8665 Non-Axiomatic Logic: A Model of Intelligent Reasoning], procedural reasoning in NARS is also discussed in [http://www.degruyter.com/view/j/jagi.2012.3.issue-3/v10229-011-0021-5/v10229-011-0021-5.xml?format=INT Solving a Problem With or Without a Program]. A previous implementation exists as version 1.3.3, with [https://code.google.com/p/open-nars/source/browse/trunk/nars-dist/Examples-1.3.3/ working examples in several files], as well as descriptions in [ProceduralInference], [ProceduralExamples], and [ProceduralLearning].

In nars.entity.Sentence, add a "desire" value, which is truth-value interpreted differently. The desire-value of statement S is the truth-value of S==>D, where D is a virtual statement representing a desired situation. Furthermore, add "Goal" and "Query" as two types of Sentence, and process them like "Judgment" and "Question", but using desire-value, rather than truth-value.

In all the inference rules, "Query/Goal" and "Judgment/Question" are processed in parallel. Most of the code for this already exist in 1.3.3, and only need to be revised.

Given the reversibility of the inference rules of NAL, the derivation of Goals and Quests are basically the existing rules, except that the desire-values are calculated using different functions, according to the above correspondence between truth-value and desire-value. 

Though both Question and Goal are derived by backward inference, there is a major difference between the two: while derived Questions are directly accepted as new tasks, derived Goals do not immediately become tasks. instead, they contribute to the desirability of the corresponding sentences. Only when the desirability of a sentence reach a threshold, does a decision-making rule is triggered to decide whether to pursue the sentence as a goal.

*Issue*: In the current issue, the decision-making rule only take the desire-value into account, while as described in the book, the plausibility of the goal should be considered, too. The problem is to find an reasonable way to calculate it.

Goals are eventually achieved by the execution of operations. An "operation" package will be introduced, with each operator defined as a class, with an "execute" method that takes a list of arguments for the operation. In Memory, a HashMap<String, Operator> will be used to remember the operators. When a task corresponds to an operation, the execute method is called.

An operation with acquired operator _oper_ and arguments _args_ is internally represented as an Inheritance statement _(`*`, args, SELF) --> oper_, though at the I/O interface it is displayed as _(oper, args)_. Here _SELF_ is a special term representing the system itself.

This part of the system will be further extended into a "universal sensorimotor interface", so that the commands or functions of other systems or decides can be registered in NARS, and called by it. With each operator, some initial knowledge about its preconditions and consequences should be provided to the system.

In summery, there will be three types of operators in NARS that share the format _(oper, args)_:
  * *Native operators*, the connectors of CompoundTerms that are directly recognized and processed by the grammar rules and inference rules
  * *Standard operators*,  the operators to be introduced in NAL-9, and equipped in every normal NARS implementation
  * *Optional operators*,  the specific operators that turn a standard NARS into a customized NARS+ described in the book

= Introspective inference (NAL-9) =

A previous preliminary implementation exists as version 1.4.0, and explained briefly in [OpenNarsOneDotFour].

This layer of NAL will be mainly implemented as a set of mental operations whose major consequences are within the system itself. These operations carries out various types of self-monitoring and self-control.

As planned for version 1.4, a few indicators are used to measure the current status of the system as a whole:
  * _happyness_: a weighted average satisfaction values (i.e., the quality of its current solution) of the recently pursued goals
  * _busyness_: a weighted average priority values of the recently processed tasks

Here "recentness" is defined as a system parameter, which can indicate either an attention span or the proportion of the newest item in the overall measurement. Probably the latter is better.

The current value of either _happyness_ or _busyness_ can be detected by a _feeling_ operations, and the results become parts of the system's _inner experience_, and will be processed in the same way as the external experience coming from the outside.

*Issue*: The desire-value of non-statement terms should also be used to prepare the system's attitude toward the term.

Other monitoring operations include:
  * anticipate: get a task from the task buffer matching a given pattern
  * know: find the truth-value of a statement
  * assess: find the desire-value of a statement

The following control operations will be implemented:
  * believe: create a judgment with a given statement
  * want: create a goal with a given statement
  * wonder: create a question with a given statement 
  * evaluate: create a query with a given statement 
  * doubt: decrease the confidence of a belief
  * hesitate: decrease the confidence of a goal
  * remind: activate a concept
  * consider: do a step of inference on a concept
  * infer: carry out an inference step with the given statements as premises

The name of a mental operator only roughly corresponds to its meaning. The exact meaning of an operator is revealed by its preconditions and consequences.

There are some other mental operations under consideration, but will not be attempted in this version.


= Memory and control =

Beside the main memory and existing task buffers for input tasks and tasks with novel (no-existing) concepts, new storage structures will be added for
  * recent events, as a Queue
  * operation registry, as a HashMap
  * global indicators, including _happyness_ and _busyness_

The control mechanism will be revised to allow the mental operations to change the default working procedure and the resource allocation policy.


= Software structure =

Since the main purpose of this version is still to test the conceptual design of NARS, especially Narsese and NAL, the software development should focus in the functionality of the design, rather than on the quality of code as asked for practical applications. Changes purely for software design reasons will be postponed to future versions.

One task is to analyze and compare the versions of open-nars, and merge them into a single trunk at the project website, with optional parts that are clearly documented.

One optional task is to explore the structure for NARS to call other systems, as well as for other systems to call NARS for reasoning service.