#summary Example Programs using OpenNARS as AI.

= Introduction =

Since NARS is now very stable and has reached a certain value of stability and completeness, we decided to create first application examples, also to proof that NARS works in domains where usual a lot of domain knowledge and special algorithms are needed, also domains where usually numerical learning algorithms are applied are shown. In all these examples, NARS is used and no special domain knowledge is input. (altough NARS can make use of such knowledge)
Usually AI in such domains is unable to master other such domains without programmatical changes and reconfigurations, or even more important, is not able to take knowledge from one domain to the other even if some situations might be similar and be solveable by similar solutions.


= Test Chamber =

This our most complex application example, there you can built arbitrary logic circuits, combine doors and lights with switches, create maschines which produce pizza, build arbitrary mazes the system has to solve on the fly, where the structure of the circuits are not known to NARS (if not especially told).
This example will one day show the difference between narrow AI and general AI very clearly, and already now is a source of very interesting results. One of the ultimate goal of this example is not only to be a training camp for AGI, but to be able to distinguish between AGI which is able to build meaningful tests for mind-wise weaker AGI's to test different cognitive abilities, and those who can not.

http://open-nars.googlecode.com/svn/trunk/wiki/TestChamber.png


= Rover =

This is a usual reinforcement learning example, except that the input space is so complex that usually a classifier is applied. NARS has to correlate sequences of actions itself with getting the reward from its body when a object has been catched, like a simple lifeform searching for food, driven by body rewards.

http://open-nars.googlecode.com/svn/trunk/wiki/Rover.png

= Tic Tac Toe =

This example is our first board game. Board games have a lot of implicit assumptions we are not aware of when we play them: Objects stay were they are until someone moves them. The board situations is most times not dependent on time at all, most times not even on how the situation looked like previously. When a stone is at a certain position there can't be another one at the same place, not can a stone be at different positions in the same game situation. Randomized things may not happen for a certain reason even if there is always some artifical reason to find for something happening. This example shows the extreme case, where not only the board game rules have to be learnt, but also typical assumptions of board games itself.

http://open-nars.googlecode.com/svn/trunk/wiki/NarTacToe.png

= Nario =

More complex games like jump&runs usually have a lot from above, logical strict coherences in the environment, physical dynamics, partial observability, and so on. AI which plays such games usually knows everything (has a complete model), or has tremendous training time or computational resources in order to deal with such domains. Here you can watch NARS starting from no knowledge, learning to jump over obstacles and so on.

http://open-nars.googlecode.com/svn/trunk/wiki/Nario.png

= Predict =

This example uses NARS to predict the future values of a observed curve:
This is where knowledge about often used functions like sinus can help a lot,
but also here we decided to don't tell the system about anything by default,
so that it has to built logic on how the values may behave in future entirely on its own.

http://open-nars.googlecode.com/svn/trunk/wiki/Predict.png