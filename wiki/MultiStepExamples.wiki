#summary Inference Examples
#labels Phase-QA

This file contains a group of multi-step inference examples, which show the
expressive and inferential capability of NARS.

Each example starts at a line with a "{{{*}}}" to empty the memory of the system. 
To run an example, copy/paste the input lines into the input window of the NARS. 
Listed after the input lines are the lines displayed in the main window of NARS during the processing of the input, followed by a brief explanation of the example.

To only display the relevant output, in the main window of NARS go to menu item "Paremeter", then select "Report Silence Level", and move the scrollbar to its right-most position (value 100). Click "Hide" to finish the change.

----
===Choice===
Input:
{{{
*
<robin --> bird>.
10
<penguin --> bird>. %0.8%
10
<swan --> bird>. %1;0.8%
10
<?x --> bird>?
150
}}}
Display:
{{{
  IN: <robin --> bird>. %1.00;0.90% {0: 1} 
10
  IN: <penguin --> bird>. %0.80;0.90% {10: 2} 
10
  IN: <swan --> bird>. %1.00;0.80% {20: 3} 
10
  IN: <?1 --> bird>?  {30: 4} 
31
 OUT: <swan --> bird>. %1.00;0.80% {20: 3} 
92
 OUT: <robin --> bird>. %1.00;0.90% {0: 1}
}}}
When a question has more than one candidate answers, their order of evaluation 
is highly context-sensative. The system reports the best it has found so far, 
and therefore may report more than one answer to a given question. In this example,
the system will settle down at the last answer even if it is given longer time.

----
===Contradiction===
Input:
{{{
*
<coffee --> beverage>.
<Java --> coffee>.
(--,<Java --> coffee>).
10 
<Java --> coffee>?
10
<tea --> beverage>?
10
<coffee --> beverage>?
10
}}}
Display:
{{{
  IN: <coffee --> beverage>. %1.00;0.90% {0: 1} 
  IN: <Java --> coffee>. %1.00;0.90% {0: 2} 
  IN: (--,<Java --> coffee>). %1.00;0.90% {0: 3} 
10
  IN: <Java --> coffee>?  {10: 4} 
1
 OUT: <Java --> coffee>. %0.50;0.95% {6: 3;2} 
9
  IN: <tea --> beverage>?  {20: 5} 
10
  IN: <coffee --> beverage>?  {30: 6} 
1
 OUT: <coffee --> beverage>. %1.00;0.90% {0: 1} 
}}}
A contradiction makes the system unsure on directly related questions, but will
not make the system to derive an arbitrary conclusion on other questions, as in 
propositional logic.

----
===Confidence and revision===
Input:
{{{
*
<Willy {-- swimmer>.
<fish --> swimmer>.
<Willy {-- fish>?
10
<Willy {-- whale>.
<whale --] black>.
<Willy {-] black>?
20  
<Willy {-] black>. %0%
<Willy {-- fish>. %0%
10
}}}
Display:
{{{
  IN: <{Willy} --> swimmer>. %1.00;0.90% {0: 1} 
  IN: <fish --> swimmer>. %1.00;0.90% {0: 2} 
  IN: <{Willy} --> fish>?  {0: 3} 
2
 OUT: <{Willy} --> fish>. %1.00;0.45% {1: 1;2} 
8
  IN: <{Willy} --> whale>. %1.00;0.90% {10: 4} 
  IN: <whale --> [black]>. %1.00;0.90% {10: 5} 
  IN: <{Willy} --> [black]>?  {10: 6} 
3
 OUT: <{Willy} --> [black]>. %1.00;0.81% {12: 4;5} 
17
  IN: <{Willy} --> [black]>. %0.00;0.90% {30: 7} 
  IN: <{Willy} --> fish>. %0.00;0.90% {30: 8} 
1
 OUT: <{Willy} --> [black]>. %0.00;0.90% {30: 7} 
 OUT: <{Willy} --> fish>. %0.00;0.90% {30: 8} 
1
 OUT: <{Willy} --> [black]>. %0.32;0.93% {31: 4;7;5} 
 OUT: <{Willy} --> fish>. %0.08;0.91% {31: 1;8;2}
}}}
Even when all the input judgments using the default confidence value, different rules
produce conclusions with difference confidence, which have different sensitivity when
facing the same amount of new evidence.

----
===Deduction chain===
Input:
{{{
*
<Tweety {-- robin>.
<robin --> bird>.
<bird --> animal>.
10 
<Tweety {-- bird>?
10
<Tweety {-- animal>?
10
}}}
Display:
{{{
  IN: <{Tweety} --> robin>. %1.00;0.90% {0: 1} 
  IN: <robin --> bird>. %1.00;0.90% {0: 2} 
  IN: <bird --> animal>. %1.00;0.90% {0: 3} 
10
  IN: <{Tweety} --> bird>?  {10: 4} 
1
 OUT: <{Tweety} --> bird>. %1.00;0.81% {1: 1;2} 
9
  IN: <{Tweety} --> animal>?  {20: 5} 
1
 OUT: <{Tweety} --> animal>. %1.00;0.73% {9: 1;3;2} 
}}}
The conclusion of a previous step may be used as a premise in a following step.
In the example, though both answers are positive (with frequency 1), their
confidence is getting lower as the deduction chain gets longer.

----
===Resemblance Chain===
Input:
{{{
*
<dog <-> cat>. %0.9%
<cat <-> tiger>. %0.9%
<tiger <-> lion>. %0.9%
<dog <-> lion>?
10
}}}
Display:
{{{
  IN: <cat <-> dog>. %0.90;0.90% {0: 1} 
  IN: <cat <-> tiger>. %0.90;0.90% {0: 2} 
  IN: <lion <-> tiger>. %0.90;0.90% {0: 3} 
  IN: <dog <-> lion>?  {0: 4} 
5
 OUT: <dog <-> lion>. %0.73;0.71% {4: 2;1;3} 
}}}
Given incomplete similarity, both frequency and the confidence decrease 
alone an inference chain.

----
===Induction and revision===
Input:
{{{
*
<bird --> swimmer>?
<swimmer --> bird>? 
1
<swan --> bird>.
<swan --> swimmer>.
10 
<gull --> bird>.
<gull --> swimmer>.
10
<crow --> bird>.
(--, <crow --> swimmer>).
40
}}}
Display:
{{{
  IN: <bird --> swimmer>?  {0: 1} 
  IN: <swimmer --> bird>?  {0: 2} 
1
  IN: <swan --> bird>. %1.00;0.90% {1: 3} 
  IN: <swan --> swimmer>. %1.00;0.90% {1: 4} 
3
 OUT: <swimmer --> bird>. %1.00;0.45% {3: 3;4} 
 OUT: <bird --> swimmer>. %1.00;0.45% {3: 3;4} 
7
  IN: <gull --> bird>. %1.00;0.90% {11: 5} 
  IN: <gull --> swimmer>. %1.00;0.90% {11: 6} 
5
 OUT: <swimmer --> bird>. %1.00;0.56% {15: 5;3;6;4} 
 OUT: <swimmer --> bird>. %1.00;0.62% {15: 5;3;6;4} 
 OUT: <bird --> swimmer>. %1.00;0.56% {15: 5;3;6;4} 
 OUT: <bird --> swimmer>. %1.00;0.62% {15: 5;3;6;4} 
5
  IN: <crow --> bird>. %1.00;0.90% {21: 7} 
  IN: (--,<crow --> swimmer>). %1.00;0.90% {21: 8} 
31
 OUT: <bird --> swimmer>. %0.61;0.67% {51: 5;7;3;8;6;4} 
 OUT: <bird --> swimmer>. %0.67;0.71% {51: 5;7;3;8;6;4} 
}}}
(1) Question may still be remembered before available knowledge arrives, or after 
answers are reported;
(2) The system can change its mind when new evidence is taken into consideration;
(3) Positive evidence has the same effect on symmetric inductive conclusions, but
negative evidence does not.

----
===Mixed Inference===
Input:
{{{
*
<swan --> bird>.
<swan --> swimmer>.
10
<gull --> bird>.
<gull --> swimmer>.
20
<robin --] feathered>.
<bird --] feathered>.
50
<robin --> swimmer>?
300
}}}
Display:
{{{
  IN: <swan --> bird>. %1.00;0.90% {0: 1} 
  IN: <swan --> swimmer>. %1.00;0.90% {0: 2} 
10
  IN: <gull --> bird>. %1.00;0.90% {10: 3} 
  IN: <gull --> swimmer>. %1.00;0.90% {10: 4} 
20
  IN: <robin --> [feathered]>. %1.00;0.90% {30: 5} 
  IN: <bird --> [feathered]>. %1.00;0.90% {30: 6} 
50
  IN: <robin --> swimmer>?  {80: 7} 
1
 OUT: <robin --> swimmer>. %1.00;0.17% {42: 3;5;4;6} 
 OUT: <robin --> swimmer>. %1.00;0.22% {64: 3;5;1;6;4;2} 
132
 OUT: <robin --> swimmer>. %1.00;0.28% {212: 4;5;1;6;3;2} 
99
 OUT: <robin --> swimmer>. %1.00;0.32% {311: 3;5;6;1;4;2} 
}}}
The final conclusion is produced using induction, abduction, deduction, and revision.
The selection of inference rule is data driven, not specified explicitly in the
input. There is no guarantee that all relevant evidence will be taken into consideration.

----
===Compositionality===
Input:
{{{
*
<light --> traffic_signal>. %0.1% 
<[red] --> traffic_signal>. %0.1% 
10
<(&, [red], light) --> traffic_signal>?
10 
<light_1 {-- (&, [red], light)>.
<light_1 {-- traffic_signal>.
10
<light_2 {-- (&, [red], light)>.
<light_2 {-- traffic_signal>.
20
}}}
Display:
{{{
  IN: <light --> traffic_signal>. %0.10;0.90% {0: 1} 
  IN: <[red] --> traffic_signal>. %0.10;0.90% {0: 2} 
10
  IN: <(&,[red],light) --> traffic_signal>?  {10: 3} 
1
 OUT: <(&,[red],light) --> traffic_signal>. %0.19;0.83% {2: 2;1} 
9
  IN: <{light_1} --> (&,[red],light)>. %1.00;0.90% {20: 4} 
  IN: <{light_1} --> traffic_signal>. %1.00;0.90% {20: 5} 
4
 OUT: <(&,[red],light) --> traffic_signal>. %0.31;0.85% {23: 5;2;4;1} 
6
  IN: <{light_2} --> (&,[red],light)>. %1.00;0.90% {30: 6} 
  IN: <{light_2} --> traffic_signal>. %1.00;0.90% {30: 7} 
9
 OUT: <(&,[red],light) --> traffic_signal>. %0.39;0.87% {38: 5;7;2;6;4;1} 
}}}
Initially, the meaning of compound term "(&,[red],light)" is determined by the
meaning of its components "red" and "light", but it will no longer be the case
when the system gets experience about the compound that cannot be reduced to its
components.

----
===Fuzzy Concept===
Input:
{{{
*
<John {-- boy>.
<John {-- (/, taller_than, {Tom}, _)>.
10
<Tom {-- (/, taller_than, _, boy)>?
100
<David {-- boy>.
(--, <David {-- (/, taller_than, {Tom}, _)>).
50
<Karl {-- boy>.
<Karl {-- (/, taller_than, {Tom}, _)>. 
300
}}}
Display:
{{{
  IN: <{John} --> boy>. %1.00;0.90% {0: 1} 
  IN: <{John} --> (/,taller_than,{Tom},_)>. %1.00;0.90% {0: 2} 
10
  IN: <{Tom} --> (/,taller_than,_,boy)>?  {10: 3} 
88
 OUT: <{Tom} --> (/,taller_than,_,boy)>. %1.00;0.45% {97: 1;2} 
12
  IN: <{David} --> boy>. %1.00;0.90% {110: 4} 
  IN: (--,<{David} --> (/,taller_than,{Tom},_)>). %1.00;0.90% {110: 5} 
49
 OUT: <{Tom} --> (/,taller_than,_,boy)>. %0.50;0.62% {126: 4;1;5;2} 
1
  IN: <{Karl} --> boy>. %1.00;0.90% {160: 6} 
  IN: <{Karl} --> (/,taller_than,{Tom},_)>. %1.00;0.90% {160: 7} 
207
 OUT: <{Tom} --> (/,taller_than,_,boy)>. %0.67;0.71% {173: 6;4;1;5;7;2} 
}}}
John's degree of membership to fuzzy concept "tall boy" depends on the extent 
to which he is taller than the other boys, determined according to available
evidence.